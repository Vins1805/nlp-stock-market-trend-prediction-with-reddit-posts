{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import dateutil.relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"/Users/Vincent/Desktop/nlp-stock-market-trend-prediction-with-reddit-posts/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_symbols = pd.read_pickle(filepath + \"symbols.pd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_symbols[\"Symbol\"] = df_symbols[\"Symbol\"].astype(str).apply(lambda sym: sym.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Description</th>\n",
       "      <th>STOCK_EXCHANGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>aaa</td>\n",
       "      <td>First Priority Clo Bond ETF</td>\n",
       "      <td>AMEX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>aaau</td>\n",
       "      <td>GS Physical Gold ETF</td>\n",
       "      <td>AMEX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>aamc</td>\n",
       "      <td>Altisource Asset</td>\n",
       "      <td>AMEX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>aau</td>\n",
       "      <td>Almaden Minerals</td>\n",
       "      <td>AMEX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>abeq</td>\n",
       "      <td>Absolute Core Strategy ETF</td>\n",
       "      <td>AMEX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index Symbol                  Description STOCK_EXCHANGE\n",
       "0      0    aaa  First Priority Clo Bond ETF           AMEX\n",
       "1      1   aaau         GS Physical Gold ETF           AMEX\n",
       "2      2   aamc             Altisource Asset           AMEX\n",
       "3      3    aau             Almaden Minerals           AMEX\n",
       "4      4   abeq   Absolute Core Strategy ETF           AMEX"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_symbols.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load reddit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.tools import Reddit\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Reddit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wallstreetbets'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\"id\", \"created_at\", \"title\", \"selftext\", \"score\", \"permalink\", \"num_comments\", \"ups\", \"upvote_ratio\", \"total_awards_received\"]\n",
    "\n",
    "subreddit = r.subreddits[-2]\n",
    "subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_pickle(filepath + \"wallstreetbets.pd\")\n",
    "df = r.load_raw_text(os.path.join(r.filepath, subreddit, \"new\"), cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"has_selftext\"] = list(map(int, df.selftext.str.len() != 0))\n",
    "df[\"downs\"] = df[[\"ups\", \"upvote_ratio\"]].apply(lambda row: row[0]/row[1] - row[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>score</th>\n",
       "      <th>permalink</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>ups</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>total_awards_received</th>\n",
       "      <th>has_selftext</th>\n",
       "      <th>downs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t3_pazmes</td>\n",
       "      <td>2021-08-25</td>\n",
       "      <td>$BB BlackBerry the sleeping giant (Potential $...</td>\n",
       "      <td>**My fellow APES** üêµ **just remember that DIAM...</td>\n",
       "      <td>1082.0</td>\n",
       "      <td>/r/wallstreetbets/comments/pazmes/bb_blackberr...</td>\n",
       "      <td>188.0</td>\n",
       "      <td>1082.0</td>\n",
       "      <td>0.87</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>161.678161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t3_pb21jz</td>\n",
       "      <td>2021-08-25</td>\n",
       "      <td>FINRA VIOLATION - JP Morgan didn't enforce cov...</td>\n",
       "      <td>[FINRA violation pdf](https://www.finra.org/si...</td>\n",
       "      <td>102.0</td>\n",
       "      <td>/r/wallstreetbets/comments/pb21jz/finra_violat...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.154639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t3_pb1v1v</td>\n",
       "      <td>2021-08-25</td>\n",
       "      <td>After being in hibernation since 2010 I think ...</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>/r/wallstreetbets/comments/pb1v1v/after_being_...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.960784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t3_pb1sa3</td>\n",
       "      <td>2021-08-25</td>\n",
       "      <td>Urban Outfitters $URBN Releases Quarterly Earn...</td>\n",
       "      <td>RECORD EARNINGS this quarter! Back when May 25...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>/r/wallstreetbets/comments/pb1sa3/urban_outfit...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.557377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t3_pb1iqr</td>\n",
       "      <td>2021-08-25</td>\n",
       "      <td>600k worth of CLNE YOLO</td>\n",
       "      <td></td>\n",
       "      <td>84.0</td>\n",
       "      <td>/r/wallstreetbets/comments/pb1iqr/600k_worth_o...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.703704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  created_at                                              title  \\\n",
       "0  t3_pazmes  2021-08-25  $BB BlackBerry the sleeping giant (Potential $...   \n",
       "1  t3_pb21jz  2021-08-25  FINRA VIOLATION - JP Morgan didn't enforce cov...   \n",
       "2  t3_pb1v1v  2021-08-25  After being in hibernation since 2010 I think ...   \n",
       "3  t3_pb1sa3  2021-08-25  Urban Outfitters $URBN Releases Quarterly Earn...   \n",
       "4  t3_pb1iqr  2021-08-25                            600k worth of CLNE YOLO   \n",
       "\n",
       "                                            selftext   score  \\\n",
       "0  **My fellow APES** üêµ **just remember that DIAM...  1082.0   \n",
       "1  [FINRA violation pdf](https://www.finra.org/si...   102.0   \n",
       "2                                                        1.0   \n",
       "3  RECORD EARNINGS this quarter! Back when May 25...     4.0   \n",
       "4                                                       84.0   \n",
       "\n",
       "                                           permalink  num_comments     ups  \\\n",
       "0  /r/wallstreetbets/comments/pazmes/bb_blackberr...         188.0  1082.0   \n",
       "1  /r/wallstreetbets/comments/pb21jz/finra_violat...          28.0   102.0   \n",
       "2  /r/wallstreetbets/comments/pb1v1v/after_being_...          31.0     1.0   \n",
       "3  /r/wallstreetbets/comments/pb1sa3/urban_outfit...          11.0     4.0   \n",
       "4  /r/wallstreetbets/comments/pb1iqr/600k_worth_o...          37.0    84.0   \n",
       "\n",
       "   upvote_ratio  total_awards_received  has_selftext       downs  \n",
       "0          0.87                   29.0             1  161.678161  \n",
       "1          0.97                    0.0             1    3.154639  \n",
       "2          0.51                    0.0             0    0.960784  \n",
       "3          0.61                    0.0             1    2.557377  \n",
       "4          0.81                    2.0             0   19.703704  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4220, 12)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# text pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lower and remove punctuation etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emojis(text):\n",
    "    return {c for c in text if c in emoji.UNICODE_EMOJI['en']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"\\[.*\\]\", \"\", text)\n",
    "    text = re.sub(\"\\(.*\\)\", \"\", text)\n",
    "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", text)\n",
    "    text = re.sub(\"\\w*\\d\\w*\", \"\", text)\n",
    "    text = re.sub(\"\\s{2}\", \" \", text)\n",
    "    text = text.encode(\"ascii\", \"ignore\").decode(\"ascii\") # removing emojis\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"title_clean\"] = df.title.apply(cleaning)\n",
    "df[\"text_clean\"] = df.apply(lambda row: cleaning(row[\"title\"] + \" \" + row[\"selftext\"]), axis=1)\n",
    "df[\"emojis\"] = df.apply(lambda row: get_emojis(row[\"title\"] + \" \" + row[\"selftext\"]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove daily threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df.title_clean.str.contains(\"daily.*thread\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove stop words and tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Vincent\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Vincent\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\Vincent\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from nltk.corpus import words\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "stop_words.add(\"yolo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_words & set(df_symbols[\"Symbol\"].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"title_tokens\"] = df.title_clean.apply(lambda t: [token for token in word_tokenize(t) if token not in stop_words])\n",
    "df[\"text_tokens\"] = df.text_clean.apply(lambda t: [token for token in word_tokenize(t) if token not in stop_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filter stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65578"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbols = set(df_symbols[\"Symbol\"].tolist()) - set(words.words())\n",
    "symbols.add(\"wish\")\n",
    "symbols.remove(\"yolo\")\n",
    "symbols.remove(\"app\")\n",
    "len(symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"title_symbols\"] = df.title_tokens.apply(lambda tokens: [token for token in tokens if token in symbols])\n",
    "df[\"text_symbols\"] = df.text_tokens.apply(lambda tokens: [token for token in tokens if token in symbols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"title_symbols\"] = df.title_symbols.apply(Counter)\n",
    "df[\"text_symbols\"] = df.text_symbols.apply(Counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stocks(row, col):\n",
    "    title, stocks = row[col], row[\"title_symbols\"].keys()\n",
    "    for stock in stocks:\n",
    "        title = title.replace(stock, \"\")\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"title_clean_no_stocks\"] = df.apply(lambda row: remove_stocks(row, \"title_clean\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text_clean_no_stocks\"] = df.apply(lambda row: remove_stocks(row, \"text_clean\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"title_tokens_clean\"] = df.title_clean_no_stocks.apply(lambda t: [token for token in word_tokenize(t) if token not in stop_words])\n",
    "df[\"text_tokens_clean\"] = df.text_clean_no_stocks.apply(lambda t: [token for token in word_tokenize(t) if token not in stop_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sno = nltk.stem.SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"title_tokens\"] = df.title_tokens.apply(lambda tokens: [sno.stem(token) for token in tokens])\n",
    "df[\"text_tokens\"] = df.text_tokens.apply(lambda tokens: [sno.stem(token) for token in tokens])\n",
    "df[\"title_tokens_clean\"] = df.title_tokens_clean.apply(lambda tokens: [sno.stem(token) for token in tokens])\n",
    "df[\"text_tokens_clean\"] = df.text_tokens_clean.apply(lambda tokens: [sno.stem(token) for token in tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lem = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"title_tokens\"] = df.title_tokens.apply(lambda tokens: [lem.lemmatize(token, \"v\") for token in tokens])\n",
    "df[\"text_tokens\"] = df.text_tokens.apply(lambda tokens: [lem.lemmatize(token, \"v\") for token in tokens])\n",
    "df[\"title_tokens_clean\"] = df.title_tokens_clean.apply(lambda tokens: [lem.lemmatize(token, \"v\") for token in tokens])\n",
    "df[\"text_tokens_clean\"] = df.text_tokens_clean.apply(lambda tokens: [lem.lemmatize(token, \"v\") for token in tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take only entires where we have some symbols\n",
    "df_sa = df[df.title_symbols.apply(len) > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lexicon-based\n",
    "__Different lexicons__:\n",
    "* AFINN\n",
    "* Bing Liu's\n",
    "* MPQA subjectivity\n",
    "* SentiWordNet\n",
    "* VADER\n",
    "* TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AFINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from afinn import Afinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "af = Afinn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vincent\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\frame.py:3607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n"
     ]
    }
   ],
   "source": [
    "df_sa[\"AFINN_polarity\"] = df_sa.text_clean.apply(lambda text: af.score(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bing Liu's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package opinion_lexicon to\n",
      "[nltk_data]     C:\\Users\\Vincent\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package opinion_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"opinion_lexicon\")\n",
    "from nltk.corpus import opinion_lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = set(opinion_lexicon.positive())\n",
    "neg = set(opinion_lexicon.negative())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sa[\"Bing_Liu_polarity\"] = df_sa.text_tokens.apply(lambda tokens: sum(1 if token in pos else -1 if token in neg else 0 for token in tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Vincent\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sa[\"VADER_polarity\"] = df_sa.text_clean.apply(lambda text: sid.polarity_scores(text)[\"compound\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sa[\"TextBlob_polarity\"] = df_sa.text_clean.apply(lambda text: TextBlob(text).polarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding (CBOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vincent\\AppData\\Roaming\\Python\\Python37\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class callback(CallbackAny2Vec):\n",
    "    \"\"\"\n",
    "    Callback to print loss after each epoch\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "        self.loss_history = list()\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        loss = model.get_latest_training_loss()\n",
    "        if self.epoch == 0:\n",
    "            self.loss_history.append(loss)\n",
    "            #print('Loss after epoch {}: {}'.format(self.epoch, loss))\n",
    "        else:\n",
    "            self.loss_history.append(loss- self.loss_previous_step)\n",
    "            #print('Loss after epoch {}: {}'.format(self.epoch, loss- self.loss_previous_step))\n",
    "        self.epoch += 1\n",
    "        self.loss_previous_step = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_epochs = 500\n",
    "c = callback()\n",
    "\n",
    "cbow_model = word2vec.Word2Vec(\n",
    "    df_sa.text_tokens,\n",
    "    window=2,\n",
    "    min_count=50,\n",
    "    epochs=n_epochs,\n",
    "    seed=99,\n",
    "    compute_loss=True,\n",
    "    callbacks=[c]\n",
    ")\n",
    "\n",
    "plt.plot(c.loss_history)\n",
    "#plt.xticks(list(range(n_epochs)))\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sell', 0.5864537954330444),\n",
       " ('load', 0.405522882938385),\n",
       " ('hold', 0.3981756269931793),\n",
       " ('call', 0.36973777413368225),\n",
       " ('itm', 0.35978636145591736),\n",
       " ('put', 0.35197609663009644),\n",
       " ('dip', 0.34997254610061646),\n",
       " ('ride', 0.3376378118991852),\n",
       " ('pick', 0.3146008253097534),\n",
       " ('know', 0.3045772612094879)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbow_model.wv.most_similar(positive=\"buy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58645374"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbow_model.wv.similarity(w1=\"buy\", w2=\"sell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_similarity(model, w1:str, w2:str):\n",
    "    \"\"\"similarity between two words\"\"\"\n",
    "    try:\n",
    "        return model.wv.similarity(w1=w1, w2=w2)\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vincent\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\frame.py:3607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n"
     ]
    }
   ],
   "source": [
    "df_sa[\"cbow_buy_polarity\"] = df_sa.text_tokens_clean.apply(lambda tokens: max([word_similarity(cbow_model, \"buy\", token) for token in tokens] + [0]))\n",
    "df_sa[\"cbow_sell_polarity\"] = df_sa.text_tokens_clean.apply(lambda tokens: max([word_similarity(cbow_model, \"sell\", token) for token in tokens] + [0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding (SKIP-GRAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_epochs = 500\n",
    "c = callback()\n",
    "\n",
    "sg_model = word2vec.Word2Vec(\n",
    "    df_sa.text_tokens,\n",
    "    window=2,\n",
    "    min_count=50,\n",
    "    epochs=n_epochs,\n",
    "    sg=1,\n",
    "    seed=99,\n",
    "    compute_loss=True,\n",
    "    callbacks=[c]\n",
    ")\n",
    "\n",
    "plt.plot(c.loss_history)\n",
    "#plt.xticks(list(range(n_epochs)))\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sell', 0.6690005660057068),\n",
       " ('hold', 0.4901556074619293),\n",
       " ('call', 0.45908159017562866),\n",
       " ('put', 0.44604355096817017),\n",
       " ('share', 0.4328191876411438),\n",
       " ('dip', 0.4277474284172058),\n",
       " ('stock', 0.42269012331962585),\n",
       " ('purchas', 0.4221177101135254),\n",
       " ('know', 0.4180748164653778),\n",
       " ('like', 0.41068413853645325)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sg_model.wv.most_similar(positive=\"buy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sa[\"sg_buy_polarity\"] = df_sa.text_tokens_clean.apply(lambda tokens: max([word_similarity(sg_model, \"buy\", token) for token in tokens] + [0]))\n",
    "df_sa[\"sg_sell_polarity\"] = df_sa.text_tokens_clean.apply(lambda tokens: max([word_similarity(sg_model, \"sell\", token) for token in tokens] + [0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python -m pip install https://github.com/FintelLabs/emosent-py/archive/e5788e73e88f691b44fd5f6eda72187b559d99f2.tar.gz\n",
    "from emosent import get_emoji_sentiment_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emoji_score(emoji):\n",
    "    try:\n",
    "        return get_emoji_sentiment_rank(emoji)[\"sentiment_score\"]\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sa[\"emoji_polarity\"] = df_sa.emojis.apply(lambda emojis: max([get_emoji_score(emoji) for emoji in emojis] + [0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "      <th>AFINN_polarity</th>\n",
       "      <th>Bing_Liu_polarity</th>\n",
       "      <th>VADER_polarity</th>\n",
       "      <th>TextBlob_polarity</th>\n",
       "      <th>cbow_buy_polarity</th>\n",
       "      <th>cbow_sell_polarity</th>\n",
       "      <th>sg_buy_polarity</th>\n",
       "      <th>sg_sell_polarity</th>\n",
       "      <th>emoji_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bb blackberry the sleeping giant  my fellow ap...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.9982</td>\n",
       "      <td>0.251447</td>\n",
       "      <td>0.586454</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.669001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finra violation jp morgan didnt enforce coveri...</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>-12</td>\n",
       "      <td>-0.9835</td>\n",
       "      <td>-0.098769</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.586454</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.669001</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>urban outfitters urbn releases quarterly earni...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.2023</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>0.290377</td>\n",
       "      <td>0.283887</td>\n",
       "      <td>0.432819</td>\n",
       "      <td>0.411581</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>worth of clne yolo</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4588</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.095611</td>\n",
       "      <td>0.101577</td>\n",
       "      <td>0.150936</td>\n",
       "      <td>0.140760</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gme gang to the moon</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.174183</td>\n",
       "      <td>0.151735</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gme baby</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>to the moon lfg hodl</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.174183</td>\n",
       "      <td>0.151735</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>light work on panw overnight</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.109719</td>\n",
       "      <td>0.116134</td>\n",
       "      <td>0.243620</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>bb has the potential to make some serious move...</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.1851</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.586454</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.669001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>im up get the bottles out  bb</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.294367</td>\n",
       "      <td>0.239921</td>\n",
       "      <td>0.392485</td>\n",
       "      <td>0.482100</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>sofi is significantly undervalued based on val...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.6172</td>\n",
       "      <td>0.083407</td>\n",
       "      <td>0.189077</td>\n",
       "      <td>0.153242</td>\n",
       "      <td>0.386027</td>\n",
       "      <td>0.339377</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>gme yolo bagger</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>since its cool to post gme gain again sold nak...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.6908</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>gme call options go brrrr</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.369738</td>\n",
       "      <td>0.363933</td>\n",
       "      <td>0.459082</td>\n",
       "      <td>0.505979</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>is it cool to post gme gains again</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5719</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.051318</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.212117</td>\n",
       "      <td>0.205762</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>edu primed for gains</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.119104</td>\n",
       "      <td>0.158252</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>to be frank i enjoy the amc stock</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.258719</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.422690</td>\n",
       "      <td>0.238070</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>edu prime for gains chinese stocks have plumme...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-2</td>\n",
       "      <td>0.7222</td>\n",
       "      <td>0.035882</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.586454</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.669001</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>nice gain so far ive taken some lumps on baba ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8442</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.294367</td>\n",
       "      <td>0.239921</td>\n",
       "      <td>0.392485</td>\n",
       "      <td>0.482100</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>on jd</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>infrastructure bill yolo on evgo part ii elect...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062215</td>\n",
       "      <td>0.112429</td>\n",
       "      <td>0.149101</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>gme gang is back</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052568</td>\n",
       "      <td>0.246702</td>\n",
       "      <td>0.362304</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>tsm yolo   left myself to drink away the pain ...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004977</td>\n",
       "      <td>0.145656</td>\n",
       "      <td>0.087109</td>\n",
       "      <td>0.187803</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>i hate to be a gay bear this trace is taken fr...</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-0.7506</td>\n",
       "      <td>-0.191667</td>\n",
       "      <td>0.137085</td>\n",
       "      <td>0.103649</td>\n",
       "      <td>0.296969</td>\n",
       "      <td>0.272544</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>crwd gains</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.119104</td>\n",
       "      <td>0.158252</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>spent on gme  at pm im up in two hours</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.187775</td>\n",
       "      <td>0.119190</td>\n",
       "      <td>0.326875</td>\n",
       "      <td>0.211967</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>defense play pltr disclaimer my position pltr ...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9879</td>\n",
       "      <td>0.133117</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.586454</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.669001</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>gme weeklies</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.253612</td>\n",
       "      <td>0.196024</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>lets see how this pans out rsi the gambling go...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.196066</td>\n",
       "      <td>0.042624</td>\n",
       "      <td>0.315669</td>\n",
       "      <td>0.260546</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>dark pools liquidity taker amp some shitty bab...</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-0.7014</td>\n",
       "      <td>0.085381</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>first time dd research on wendys restaurants w...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.9816</td>\n",
       "      <td>0.162074</td>\n",
       "      <td>0.369738</td>\n",
       "      <td>0.363933</td>\n",
       "      <td>0.459082</td>\n",
       "      <td>0.505979</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>tesla wins and losses how do i flag this oh we...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4767</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.337638</td>\n",
       "      <td>0.211230</td>\n",
       "      <td>0.347511</td>\n",
       "      <td>0.240063</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>jd gain</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5267</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.119104</td>\n",
       "      <td>0.158252</td>\n",
       "      <td>0.221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>upst crash yolo update getting destroyed by de...</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-3</td>\n",
       "      <td>-0.7351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.351976</td>\n",
       "      <td>0.285141</td>\n",
       "      <td>0.446044</td>\n",
       "      <td>0.482100</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>reasons to buy amzn november calls ahead of e...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9936</td>\n",
       "      <td>0.072695</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>my first be gentle one trade that made back al...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.586454</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.669001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>jnj is primed to follow in pfe footsteps ok he...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>0.159184</td>\n",
       "      <td>0.369738</td>\n",
       "      <td>0.363933</td>\n",
       "      <td>0.459082</td>\n",
       "      <td>0.505979</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>clne yolo</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>profit on next weeks gme calls</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.369738</td>\n",
       "      <td>0.363933</td>\n",
       "      <td>0.459082</td>\n",
       "      <td>0.505979</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>gme calls yolo turning to in a day</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.369738</td>\n",
       "      <td>0.363933</td>\n",
       "      <td>0.459082</td>\n",
       "      <td>0.505979</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>amc call options yolo</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.369738</td>\n",
       "      <td>0.363933</td>\n",
       "      <td>0.459082</td>\n",
       "      <td>0.505979</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>they said not to play gme short options on mar...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.6293</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.200487</td>\n",
       "      <td>0.175737</td>\n",
       "      <td>0.392303</td>\n",
       "      <td>0.317936</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>gme may be a small amount but i had a good gut...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6808</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.087271</td>\n",
       "      <td>0.163699</td>\n",
       "      <td>0.215454</td>\n",
       "      <td>0.207379</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>amc to this week</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.253612</td>\n",
       "      <td>0.196024</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>abnb weekly put yolo</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.351976</td>\n",
       "      <td>0.285141</td>\n",
       "      <td>0.446044</td>\n",
       "      <td>0.455166</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>pfe buying tril will amarin be next pfizer to ...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-0.8166</td>\n",
       "      <td>0.047035</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>gme yolo beard bet update in short its been aw...</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>-26</td>\n",
       "      <td>0.8623</td>\n",
       "      <td>0.060545</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.586454</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.669001</td>\n",
       "      <td>0.534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>thanks nvda</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.125786</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.135470</td>\n",
       "      <td>0.077597</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>goco were things that bad down growth sales be...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.9950</td>\n",
       "      <td>0.019246</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.586454</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.669001</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>pfe premarket posttaco bell toilet talk as i h...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9851</td>\n",
       "      <td>0.037061</td>\n",
       "      <td>0.398176</td>\n",
       "      <td>0.363933</td>\n",
       "      <td>0.490156</td>\n",
       "      <td>0.505979</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            text_clean  AFINN_polarity  \\\n",
       "0    bb blackberry the sleeping giant  my fellow ap...            30.0   \n",
       "1    finra violation jp morgan didnt enforce coveri...           -30.0   \n",
       "3    urban outfitters urbn releases quarterly earni...             0.0   \n",
       "4                                  worth of clne yolo              2.0   \n",
       "6                                gme gang to the moon              0.0   \n",
       "8                                            gme baby              0.0   \n",
       "9                                to the moon lfg hodl              0.0   \n",
       "17                       light work on panw overnight              0.0   \n",
       "19   bb has the potential to make some serious move...            -5.0   \n",
       "21                      im up get the bottles out  bb              0.0   \n",
       "23   sofi is significantly undervalued based on val...            11.0   \n",
       "26                                    gme yolo bagger              0.0   \n",
       "28   since its cool to post gme gain again sold nak...             3.0   \n",
       "29                          gme call options go brrrr              0.0   \n",
       "32                 is it cool to post gme gains again              3.0   \n",
       "34                               edu primed for gains              2.0   \n",
       "37                  to be frank i enjoy the amc stock              2.0   \n",
       "38   edu prime for gains chinese stocks have plumme...             3.0   \n",
       "41   nice gain so far ive taken some lumps on baba ...             8.0   \n",
       "42                                              on jd              0.0   \n",
       "43   infrastructure bill yolo on evgo part ii elect...             0.0   \n",
       "47                                   gme gang is back              0.0   \n",
       "48   tsm yolo   left myself to drink away the pain ...            -2.0   \n",
       "52   i hate to be a gay bear this trace is taken fr...            -5.0   \n",
       "54                                         crwd gains              2.0   \n",
       "55             spent on gme  at pm im up in two hours              0.0   \n",
       "56   defense play pltr disclaimer my position pltr ...            13.0   \n",
       "61                                       gme weeklies              0.0   \n",
       "66   lets see how this pans out rsi the gambling go...             0.0   \n",
       "72   dark pools liquidity taker amp some shitty bab...           -15.0   \n",
       "77   first time dd research on wendys restaurants w...            13.0   \n",
       "79   tesla wins and losses how do i flag this oh we...             1.0   \n",
       "81                                           jd gain               2.0   \n",
       "82   upst crash yolo update getting destroyed by de...            -7.0   \n",
       "90    reasons to buy amzn november calls ahead of e...            18.0   \n",
       "92   my first be gentle one trade that made back al...            -1.0   \n",
       "93   jnj is primed to follow in pfe footsteps ok he...            -2.0   \n",
       "95                                          clne yolo              0.0   \n",
       "98                     profit on next weeks gme calls              2.0   \n",
       "100                gme calls yolo turning to in a day              0.0   \n",
       "101                             amc call options yolo              0.0   \n",
       "103  they said not to play gme short options on mar...            -2.0   \n",
       "104  gme may be a small amount but i had a good gut...             4.0   \n",
       "105                                  amc to this week              0.0   \n",
       "106                              abnb weekly put yolo              0.0   \n",
       "107  pfe buying tril will amarin be next pfizer to ...            -2.0   \n",
       "111  gme yolo beard bet update in short its been aw...           -37.0   \n",
       "115                                       thanks nvda              2.0   \n",
       "121  goco were things that bad down growth sales be...            11.0   \n",
       "125  pfe premarket posttaco bell toilet talk as i h...            31.0   \n",
       "\n",
       "     Bing_Liu_polarity  VADER_polarity  TextBlob_polarity  cbow_buy_polarity  \\\n",
       "0                   14          0.9982           0.251447           0.586454   \n",
       "1                  -12         -0.9835          -0.098769           1.000000   \n",
       "3                    0         -0.2023          -0.033333           0.290377   \n",
       "4                    1          0.4588           0.300000           0.095611   \n",
       "6                    0          0.0000           0.000000           0.043039   \n",
       "8                    0          0.0000           0.000000           0.000000   \n",
       "9                    0          0.0000           0.000000           0.043039   \n",
       "17                   1          0.0000           0.400000           0.000000   \n",
       "19                   2         -0.1851           0.016095           0.586454   \n",
       "21                   0          0.0000           0.000000           0.294367   \n",
       "23                  -1          0.6172           0.083407           0.189077   \n",
       "26                   0          0.2732           0.000000           0.000000   \n",
       "28                   2          0.6908           0.175000           1.000000   \n",
       "29                   0          0.0000           0.000000           0.369738   \n",
       "32                   2          0.5719           0.350000           0.051318   \n",
       "34                   1          0.3400           0.000000           0.000000   \n",
       "37                   1          0.4939           0.400000           0.258719   \n",
       "38                  -2          0.7222           0.035882           1.000000   \n",
       "41                   3          0.8442           0.230000           0.294367   \n",
       "42                   0          0.0000           0.000000           0.000000   \n",
       "43                   0          0.2732           0.000000           0.000000   \n",
       "47                   0          0.0000           0.000000           0.000000   \n",
       "48                  -1         -0.2960           0.000000           0.004977   \n",
       "52                  -2         -0.7506          -0.191667           0.137085   \n",
       "54                   1          0.3400           0.000000           0.000000   \n",
       "55                   0          0.0000          -0.100000           0.187775   \n",
       "56                   3          0.9879           0.133117           1.000000   \n",
       "61                   0          0.0000           0.000000           0.080735   \n",
       "66                  -1          0.0000           0.000000           0.196066   \n",
       "72                  -7         -0.7014           0.085381           1.000000   \n",
       "77                   7          0.9816           0.162074           0.369738   \n",
       "79                   1          0.4767           0.300000           0.337638   \n",
       "81                   1          0.5267           0.000000           0.000000   \n",
       "82                  -3         -0.7351           0.000000           0.351976   \n",
       "90                   3          0.9936           0.072695           1.000000   \n",
       "92                   0          0.5574           0.150000           0.586454   \n",
       "93                   2          0.1280           0.159184           0.369738   \n",
       "95                   0          0.2732           0.000000           0.000000   \n",
       "98                   0          0.4404           0.000000           0.369738   \n",
       "100                  0          0.2732           0.000000           0.369738   \n",
       "101                  0          0.2732           0.000000           0.369738   \n",
       "103                 -1         -0.6293          -0.250000           0.200487   \n",
       "104                  1          0.6808           0.225000           0.087271   \n",
       "105                  0          0.0000           0.000000           0.080735   \n",
       "106                  0          0.2732           0.000000           0.351976   \n",
       "107                 -2         -0.8166           0.047035           1.000000   \n",
       "111                -26          0.8623           0.060545           1.000000   \n",
       "115                  1          0.4404           0.200000           0.125786   \n",
       "121                 -1          0.9950           0.019246           1.000000   \n",
       "125                  1          0.9851           0.037061           0.398176   \n",
       "\n",
       "     cbow_sell_polarity  sg_buy_polarity  sg_sell_polarity  emoji_polarity  \n",
       "0              1.000000         0.669001          1.000000           0.621  \n",
       "1              0.586454         1.000000          0.669001           0.000  \n",
       "3              0.283887         0.432819          0.411581           0.000  \n",
       "4              0.101577         0.150936          0.140760           0.000  \n",
       "6              0.000000         0.174183          0.151735           0.000  \n",
       "8              0.000000         0.000000          0.000000           0.000  \n",
       "9              0.000000         0.174183          0.151735           0.000  \n",
       "17             0.109719         0.116134          0.243620           0.000  \n",
       "19             1.000000         0.669001          1.000000           0.000  \n",
       "21             0.239921         0.392485          0.482100           0.000  \n",
       "23             0.153242         0.386027          0.339377           0.000  \n",
       "26             0.000000         0.000000          0.000000           0.000  \n",
       "28             1.000000         1.000000          1.000000           0.000  \n",
       "29             0.363933         0.459082          0.505979           0.000  \n",
       "32             0.000000         0.212117          0.205762           0.000  \n",
       "34             0.000000         0.119104          0.158252           0.000  \n",
       "37             0.000000         0.422690          0.238070           0.000  \n",
       "38             0.586454         1.000000          0.669001           0.000  \n",
       "41             0.239921         0.392485          0.482100           0.000  \n",
       "42             0.000000         0.000000          0.000000           0.000  \n",
       "43             0.062215         0.112429          0.149101           0.000  \n",
       "47             0.052568         0.246702          0.362304           0.000  \n",
       "48             0.145656         0.087109          0.187803           0.000  \n",
       "52             0.103649         0.296969          0.272544           0.000  \n",
       "54             0.000000         0.119104          0.158252           0.000  \n",
       "55             0.119190         0.326875          0.211967           0.000  \n",
       "56             0.586454         1.000000          0.669001           0.000  \n",
       "61             0.000000         0.253612          0.196024           0.000  \n",
       "66             0.042624         0.315669          0.260546           0.000  \n",
       "72             1.000000         1.000000          1.000000           0.525  \n",
       "77             0.363933         0.459082          0.505979           0.000  \n",
       "79             0.211230         0.347511          0.240063           0.000  \n",
       "81             0.000000         0.119104          0.158252           0.221  \n",
       "82             0.285141         0.446044          0.482100           0.000  \n",
       "90             1.000000         1.000000          1.000000           0.000  \n",
       "92             1.000000         0.669001          1.000000           0.000  \n",
       "93             0.363933         0.459082          0.505979           0.000  \n",
       "95             0.000000         0.000000          0.000000           0.000  \n",
       "98             0.363933         0.459082          0.505979           0.000  \n",
       "100            0.363933         0.459082          0.505979           0.000  \n",
       "101            0.363933         0.459082          0.505979           0.000  \n",
       "103            0.175737         0.392303          0.317936           0.000  \n",
       "104            0.163699         0.215454          0.207379           0.000  \n",
       "105            0.000000         0.253612          0.196024           0.000  \n",
       "106            0.285141         0.446044          0.455166           0.000  \n",
       "107            1.000000         1.000000          1.000000           0.000  \n",
       "111            0.586454         1.000000          0.669001           0.534  \n",
       "115            0.000000         0.135470          0.077597           0.000  \n",
       "121            0.586454         1.000000          0.669001           0.000  \n",
       "125            0.363933         0.490156          0.505979           0.000  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sa[[\"text_clean\",\"AFINN_polarity\", \"Bing_Liu_polarity\", \"VADER_polarity\", \"TextBlob_polarity\", \"cbow_buy_polarity\", \"cbow_sell_polarity\", \"sg_buy_polarity\", \"sg_sell_polarity\", \"emoji_polarity\"]].head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vincent\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\frame.py:3607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n"
     ]
    }
   ],
   "source": [
    "df_sa[\"title_bigrams\"] = df_sa.title_tokens_clean.apply(lambda t: [\"_\".join(bigram) for bigram in nltk.bigrams(t)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1504 | INFO | adding document #0 to Dictionary(0 unique tokens: [])\n",
      "1504 | INFO | built Dictionary(2620 unique tokens: ['blackberri', 'giant', 'sleep', 'bag', 'compet']...) from 2048 documents (total 9649 corpus positions)\n",
      "1504 | INFO | Dictionary lifecycle event {'msg': \"built Dictionary(2620 unique tokens: ['blackberri', 'giant', 'sleep', 'bag', 'compet']...) from 2048 documents (total 9649 corpus positions)\", 'datetime': '2021-08-25T20:46:22.330642', 'gensim': '4.0.1', 'python': '3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "id2word = corpora.Dictionary(df_sa.title_tokens_clean)\n",
    "#id2word = corpora.Dictionary(df_sa.title_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [id2word.doc2bow(tokens) for tokens in df_sa.title_tokens_clean]\n",
    "#corpus = [id2word.doc2bow(tokens) for tokens in df_sa.title_bigrams]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048, 33)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuning_lda_model(n_topics, alpha=\"symmetric\", eta=None):\n",
    "    lda_model = gensim.models.ldamodel.LdaModel(\n",
    "        corpus=corpus,\n",
    "        id2word=id2word,\n",
    "        num_topics=n_topics,\n",
    "        random_state=100,\n",
    "        update_every=1,\n",
    "        chunksize=1500,\n",
    "        passes=10,\n",
    "        alpha=alpha,\n",
    "        eta=eta,\n",
    "        per_word_topics=True,\n",
    "    )\n",
    "    return lda_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # Topic parameter\n",
    "    topics = range(2,80)\n",
    "\n",
    "    # Alpha parameter\n",
    "    alpha = list(np.arange(0.01, 1, 0.05))\n",
    "    alpha.append('symmetric')\n",
    "    alpha.append('asymmetric')\n",
    "\n",
    "    # Beta parameter\n",
    "    eta = list(np.arange(0.1, 1, 0.05))\n",
    "    eta.append('symmetric')\n",
    "    \n",
    "    previous_score = 0\n",
    "    topic_scores = list()\n",
    "    for n_topics in topics:\n",
    "        lda_model = tuning_lda_model(n_topics)\n",
    "        coherence_model_lda = CoherenceModel(model=lda_model, texts=df_sa.title_tokens_clean, dictionary=id2word, coherence=\"c_v\")\n",
    "        score = coherence_model_lda.get_coherence()\n",
    "        if score > previous_score:\n",
    "            previous_score = score\n",
    "            best_n_topics = n_topics\n",
    "        topic_scores.append(score)\n",
    "        print(n_topics, score)\n",
    "    \n",
    "    plt.plot(topic_scores)\n",
    "    plt.xticks(range(len(topics)), topics, rotation=-45)\n",
    "    plt.xlabel(\"Topics\")\n",
    "    plt.ylabel(\"Coherence_score\")\n",
    "    plt.show()\n",
    "        \n",
    "    previous_score = 0\n",
    "    alpha_scores = list()\n",
    "    for a in alpha:\n",
    "        lda_model = tuning_lda_model(best_n_topics, a)\n",
    "        coherence_model_lda = CoherenceModel(model=lda_model, texts=df_sa.title_tokens_clean, dictionary=id2word, coherence=\"c_v\")\n",
    "        score = coherence_model_lda.get_coherence()\n",
    "        if score > previous_score:\n",
    "            previous_score = score\n",
    "            best_alpha = a\n",
    "        alpha_scores.append(score)\n",
    "        print(a, score)\n",
    "        \n",
    "    plt.plot(alpha_scores)\n",
    "    plt.xticks(range(len(alpha)), [round(a, 2) if type(a) == np.float64 else a for a in alpha], rotation=-45)\n",
    "    plt.xlabel(\"Alpha\")\n",
    "    plt.ylabel(\"Coherence_score\")\n",
    "    plt.show()\n",
    "        \n",
    "    previous_score = 0\n",
    "    eta_scores = list()\n",
    "    for e in eta:\n",
    "        lda_model = tuning_lda_model(n_topics, best_alpha, e)\n",
    "        coherence_model_lda = CoherenceModel(model=lda_model, texts=df_sa.title_tokens_clean, dictionary=id2word, coherence=\"c_v\")\n",
    "        score = coherence_model_lda.get_coherence()\n",
    "        if score > previous_score:\n",
    "            previous_score = score\n",
    "            best_eta = e\n",
    "        eta_scores.append(score)\n",
    "        print(e, score)\n",
    "    \n",
    "    plt.plot(eta_scores)\n",
    "    plt.xticks(range(len(eta)), [round(e, 2) if type(e) == np.float64 else e for e in eta], rotation=-45)\n",
    "    plt.xlabel(\"Eta\")\n",
    "    plt.ylabel(\"Coherence_score\")\n",
    "    plt.show()\n",
    "    \n",
    "    print(best_n_topics, best_alpha, best_eta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48622420280825857\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    lda_model = gensim.models.ldamodel.LdaModel(\n",
    "        corpus=corpus,\n",
    "        id2word=id2word,\n",
    "        num_topics=best_n_topics,\n",
    "        random_state=100,\n",
    "        update_every=1,\n",
    "        chunksize=1500,\n",
    "        passes=10,\n",
    "        alpha=best_alpha,\n",
    "        eta=best_eta,\n",
    "        per_word_topics=True)\n",
    "\n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=df_sa.title_tokens_clean, dictionary=id2word, coherence=\"c_v\")\n",
    "    print(coherence_model_lda.get_coherence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# safe model\n",
    "if False:\n",
    "    filepath = \"/Users/Vincent/Desktop/nlp-stock-market-trend-prediction-with-reddit-posts/models/lda_model.model\"\n",
    "    lda_model.save(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "if True:\n",
    "    filepath = \"/Users/Vincent/Desktop/nlp-stock-market-trend-prediction-with-reddit-posts/models/lda_model.model\"\n",
    "    lda_model = gensim.models.ldamodel.LdaModel.load(filepath)\n",
    "        \n",
    "    id2word = lda_model.id2word\n",
    "    corpus = [id2word.doc2bow(tokens) for tokens in df_sa.title_tokens_clean]\n",
    "    #lda_model[corpus]\n",
    "    \n",
    "    lda_model.update(corpus)\n",
    "    \n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=df_sa.title_tokens_clean, dictionary=id2word, coherence=\"c_v\")\n",
    "    print(coherence_model_lda.get_coherence())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__interesting topics:__\n",
    "* 3 - buy\n",
    "* 8 - earn\n",
    "* 12 - save\n",
    "* 13 - bought\n",
    "* 15 - sell\n",
    "* 16 - rise\n",
    "* 17 - moon\n",
    "* 28 - drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_definition = {\n",
    "    \"positiv\": [3,5,10,11,12,14,23],\n",
    "    \"negativ\": [6,22],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply LDA model on DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_score_threshold(tokens, threshold=0.05):\n",
    "    bow = id2word.doc2bow(tokens)\n",
    "    return [topic for topic, score in lda_model[bow][0] if score > threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sa[\"topics\"] = df_sa.title_tokens_clean.apply(lda_score_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"df_size:\", df_sa.shape[0], \"\\ndf_no_topic_found:\", sum(df_sa.topics.str.len() == 0), \"\\ndf_topics_found:\", sum(df_sa.topics.str.len() >= 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 3 stock symbols per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity_cols = df_sa.columns[df_sa.columns.str.contains(r\"polarity$\")].tolist()\n",
    "polarity_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_polarity_cols = [polarity + \"_stock_score\" for polarity in polarity_cols]\n",
    "# score is based on all symbols per day, not a subset (e.g. \"SPCE\" got 50 threads for one day, but only 20 are in the relevant ones -> but the calculation is done on the 50)\n",
    "series = df_sa[[\"title_symbols\"] + polarity_cols].apply(lambda row: [Counter({symbol: polarity for symbol in row[\"title_symbols\"]}) for polarity in row[polarity_cols]], axis=1)\n",
    "df_sa[stock_polarity_cols] = pd.DataFrame(series.tolist(), index=series.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sa[\"thread_score_per_stock\"] = df_sa[[\"title_symbols\", \"score\"]].apply(lambda row: Counter({symbol: row[\"score\"] for symbol in row[\"title_symbols\"].keys()}), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_counters(series):\n",
    "    total = Counter()\n",
    "    for counter in series.tolist():\n",
    "        if not type(counter) is Counter:\n",
    "            continue\n",
    "        total.update(counter)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = df_sa.groupby(\"created_at\")[[\"title_symbols\", \"thread_score_per_stock\"] + stock_polarity_cols].agg(update_counters)\n",
    "df_results[\"most_common_symbols\"] = df_results.title_symbols.apply(lambda counter: counter.most_common(3))\n",
    "df_results[\"unique_symbol_count\"] = df_results.title_symbols.str.len()\n",
    "\n",
    "df_results[\"most_common_thread_score\"] = df_results.thread_score_per_stock.apply(lambda counter: [(stock, value) for stock, value in counter.most_common(3) if value > 0])\n",
    "\n",
    "for col in stock_polarity_cols:\n",
    "    df_results[\"most_common_\" + col] = df_results[col].apply(lambda counter: [(stock, value) for stock, value in counter.most_common(3) if value > 0])\n",
    "    df_results[\"least_common_\" + col] = df_results[col].apply(lambda counter: [(stock, value) for stock, value in counter.most_common()[::-1] if value < 0][0:3])\n",
    "\n",
    "df_results.drop(columns=[\"title_symbols\", \"thread_score_per_stock\", \"least_common_buy_polarity_stock_score\", \"least_common_sell_polarity_stock_score\", \"least_common_emoji_polarity_stock_score\"] + stock_polarity_cols, inplace=True)\n",
    "df_results.head(100).style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lda_results = df_sa[[\"created_at\", \"title\", \"score\", \"AFINN_polarity\", \"Bing_Liu_polarity\", \"VADER_polarity\", \"TextBlob_polarity\", \"buy_polarity\", \"sell_polarity\", \"emoji_polarity\", \"has_selftext\", \"topics\", \"title_symbols\", \"num_comments\", \"ups\", \"downs\", \"upvote_ratio\", \"total_awards_received\"]].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No topics found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lda_results[df_lda_results.topics.str.len() == 0].head(200).style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### relevant topics found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda nested_list: [elm for sublist in nested_list for elm in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_topics = flatten(topics_definition.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df_lda_results.topics.apply(lambda topics: len(set(topics) & set(relevant_topics)) >= 1)\n",
    "print(sum(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lda_results[mask].head(200).style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results2 = df_results.copy()\n",
    "df_results2[\"title_symbols_relevant\"] = df_lda_results[mask].groupby(\"created_at\")[[\"title_symbols\"]].apply(lambda c: c.sum())\n",
    "df_results2[\"most_common_symbols_relevant\"] = df_results2.title_symbols_relevant.apply(lambda counter: counter.most_common(3) if type(counter) == Counter else float('nan'))\n",
    "df_results2[\"unique_symbol_count_relevant\"] = df_results2.title_symbols_relevant.str.len()\n",
    "df_results2[\"unique_symbol_count_relevant\"] = df_results2.unique_symbol_count_relevant.fillna(0).astype(int)\n",
    "df_results2.drop(columns=\"title_symbols_relevant\", inplace=True)\n",
    "df_results2.head(100).style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check topics of specific stock symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(flatten(df_sa[df_sa.title_symbols.apply(lambda c: \"spce\" in c)].topics.tolist())).most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lda_results.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add topics\n",
    "_df = df_lda_results.explode(\"topics\")\n",
    "_df[\"value\"] = ~_df.topics.isna()\n",
    "_df = _df.pivot_table(\"value\", _df.index, \"topics\").fillna(0).add_prefix(\"topic_count_\")\n",
    "df_features = pd.merge(df_lda_results, _df, left_index=True, right_index=True)\n",
    "\n",
    "# unigram\n",
    "#id2word = corpora.Dictionary(df_sa.text_tokens_clean)\n",
    "#corpus = [dict(id2word.doc2bow(tokens)) for tokens in df_sa.text_tokens_clean]\n",
    "# bigram\n",
    "#df_sa[\"text_tokens_clean_bigram\"] = df_sa.text_tokens_clean.apply(lambda t: [\"_\".join(bigram) for bigram in nltk.bigrams(t)])\n",
    "#id2word = corpora.Dictionary(df_sa.text_tokens_clean_bigram)\n",
    "#corpus = [dict(id2word.doc2bow(tokens)) for tokens in df_sa.text_tokens_clean_bigram]\n",
    "# add word ids\n",
    "#_df = pd.DataFrame(corpus).fillna(0)\n",
    "#df_features = pd.concat([df_features, _df], axis=1)\n",
    "\n",
    "# add stocks\n",
    "df_features = df_features.explode(\"title_symbols\").rename(columns={\"title_symbols\": \"stock\"})\n",
    "df_features[\"stock_thread_count\"] = 1\n",
    "df_features.drop(columns=[\"topics\", \"title\"], inplace=True)\n",
    "\n",
    "_stock_data = yf.download(df_features.stock.unique().tolist(), start=df_features.created_at.min(), end=df_features.created_at.max())\n",
    "df_features = df_features.groupby([\"stock\", \"created_at\"], as_index=False).sum()\n",
    "\n",
    "# join stock data\n",
    "#_df = _stock_data.Close.pct_change().reset_index()\n",
    "_df = _stock_data[[\"Open\", \"Close\"]].apply(lambda row: (row[\"Close\"]-row[\"Open\"])/row[\"Open\"]*100, axis=1).reset_index()\n",
    "_df[\"Date\"] =_df.Date.apply(lambda ts: ts.to_pydatetime().date())\n",
    "df_features = pd.merge(df_features, _df, left_on=\"created_at\", right_on=\"Date\")\n",
    "\n",
    "# select labels\n",
    "df_features[\"value_change\"] = df_features.apply(lambda row: row[row[\"stock\"].upper()], axis=1).fillna(0)\n",
    "df_features = df_features.drop(columns=_df.columns).sort_values(\"created_at\")\n",
    "\n",
    "# round labels\n",
    "print(\"\\nmean value change:\", df_features.value_change.abs().mean())\n",
    "print(\"median value change:\", df_features.value_change.abs().median())\n",
    "# 1=buy; 0=hold; -1=sell\n",
    "#df_features[\"labels\"] = df_features.value_change.apply(lambda x: 1 if x > .01 else -1 if x < -.01 else 0)\n",
    "df_features[\"labels\"] = df_features.value_change.apply(lambda x: 1 if x > 2 else -1 if x < -2 else 0)\n",
    "df_features = df_features.reset_index(drop=True)\n",
    "\n",
    "print()\n",
    "\n",
    "df_features.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.has_selftext.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.columns[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = df_features.copy()\n",
    "_df = _df.drop(columns=[\"stock\", \"created_at\", \"close_label\"])\n",
    "\n",
    "labels = _df[\"labels\"]\n",
    "features= _df.drop(\"labels\", axis = 1)\n",
    "feature_list = list(features.columns)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size = 0.25, random_state = 42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import plotly.express as px\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = RandomForestClassifier(n_estimators = 100,\n",
    "                                  random_state = 2,\n",
    "                                 )\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model_rf.predict(X_test)\n",
    "#errors = abs(predictions - test_labels)\n",
    "#print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training set metrics:')\n",
    "y_pred = model_rf.predict(X_train)\n",
    "print('Accuracy:', accuracy_score(y_train, y_pred))\n",
    "print('Precision:', precision_score(y_train, y_pred, average='micro'))\n",
    "print('Recall:', recall_score(y_train, y_pred, average='micro'))\n",
    "\n",
    "print('Test set metrics:')\n",
    "y_pred = model_rf.predict(X_test)\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='micro'))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_sorted_by_importance=model_rf.feature_importances_.argsort()\n",
    "feat_imp=pd.DataFrame({\n",
    "    'cols':features.columns[col_sorted_by_importance],\n",
    "    'imps':model_rf.feature_importances_[col_sorted_by_importance]\n",
    "})\n",
    "\n",
    "px.bar(feat_imp, x='cols', y='imps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nb = GaussianNB()\n",
    "model_nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "ac = accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "* testing with labels 1,0,-1 (3 output layer with a softmax)\n",
    "* testing with 1 output layer to predict (the % increase/decrease)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "* random forest: 0.34 -> 0.39 -> 0.41\n",
    "* naive bayes: 0.39\n",
    "* neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data = yf.download(other_stocks, start=df_results2.index.min(), end=df_results2.index.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_stocks.remove(\"WINS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = stock_data.Close.pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.line(test2)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt3_stock_threads = df_results2.most_common_symbols_relevant.apply(lambda c: [stock for stock, count in c if count >= 3] if type(c) is list else list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data = yf.download(top_stocks, start=df_results2.index.min(), end=df_results2.index.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = stock_data.Close.pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.line(test)\n",
    "for key, value in gt3_stock_threads.to_dict().items():\n",
    "    if not value:\n",
    "        continue\n",
    "    fig.add_vline(x=key, line_width=2, line_dash=\"dash\")\n",
    "    print(key, value)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date = datetime.datetime.now()\n",
    "start_date = end_date - dateutil.relativedelta.relativedelta(months=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_per_day = df_results2.most_common_symbols.apply(lambda stocks: stocks[0][0]).str.upper().tolist()\n",
    "top_stocks = list(set(stocks_per_day))\n",
    "#top_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "other_stocks = [stock.upper() for stock, counts in update_counters(df_sa.title_symbols).most_common(50)]\n",
    "other_stocks.remove(\"LFG\")\n",
    "other_stocks.remove(\"EV\")\n",
    "#other_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stock_data = yf.download(other_stocks, start=start_date, end=end_date)\n",
    "stock_data = yf.download(top_stocks, start=start_date, end=end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candlestick Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def candlestick(symbols):\n",
    "    if isinstance(symbols, str):\n",
    "        symbols = [symbols]\n",
    "    \n",
    "    fig = go.Figure(data=[go.Candlestick(\n",
    "        x=stock_data.index,\n",
    "        open=stock_data.Open[symbol],\n",
    "        high=stock_data.High[symbol],\n",
    "        low=stock_data.Low[symbol],\n",
    "        close=stock_data.Close[symbol],\n",
    "        name=symbol\n",
    "    ) for symbol in symbols])\n",
    "    fig.update_layout(\n",
    "        title=\", \".join(symbols),\n",
    "        xaxis_title=\"Date\",\n",
    "        yaxis_title=\"Price\",\n",
    "        legend_title=\"Stocks\",\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candlestick(unique_stocks[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Line Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line(symbols):\n",
    "    fig = px.line(stock_data.Open[symbols])\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line(unique_stocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OHLC Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ohlc(symbols):\n",
    "    if isinstance(symbols, str):\n",
    "        symbols = [symbols]\n",
    "        \n",
    "    fig = go.Figure(data=[go.Ohlc(\n",
    "        x=stock_data.index,\n",
    "        open=stock_data.Open[symbol],\n",
    "        high=stock_data.High[symbol],\n",
    "        low=stock_data.Low[symbol],\n",
    "        close=stock_data.Close[symbol],\n",
    "        name=symbol\n",
    "    ) for symbol in symbols])\n",
    "    fig.update_layout(\n",
    "        title=\", \".join(symbols),\n",
    "        xaxis_title=\"Date\",\n",
    "        yaxis_title=\"Price\",\n",
    "        legend_title=\"Stocks\",\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohlc(unique_stocks[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s.actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s.options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s.calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s.recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s.sustainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ideas for further progression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* process emojis\n",
    "* Poincar√© embeddings (https://arxiv.org/pdf/1705.08039.pdf)\n",
    "* process gifs/videos/links/images\n",
    "* more data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problems\n",
    "* classifier isn't a good solution\n",
    "    * every stock with 1% increase/decrease gets labeled as buy/sell\n",
    "    * use a model which predicts the increase/decrease amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
